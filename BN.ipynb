{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2D input tensor (Batch size: 2, Channels: 3, Height: 4, Width: 4)\n",
    "input_tensor = torch.tensor([[[[1.0, 2.0, 3.0, 4.0], \n",
    "                                [5.0, 6.0, 7.0, 8.0], \n",
    "                                [9.0, 10.0, 11.0, 12.0], \n",
    "                                [13.0, 14.0, 15.0, 16.0]],\n",
    "                               [[17.0, 18.0, 19.0, 20.0], \n",
    "                                [21.0, 22.0, 23.0, 24.0], \n",
    "                                [25.0, 26.0, 27.0, 28.0], \n",
    "                                [29.0, 30.0, 31.0, 32.0]],\n",
    "                               [[33.0, 34.0, 35.0, 36.0], \n",
    "                                [37.0, 38.0, 39.0, 40.0], \n",
    "                                [41.0, 42.0, 43.0, 44.0], \n",
    "                                [45.0, 46.0, 47.0, 48.0]]],\n",
    "                              [[[49.0, 50.0, 51.0, 52.0], \n",
    "                                [53.0, 54.0, 55.0, 56.0], \n",
    "                                [57.0, 58.0, 59.0, 60.0], \n",
    "                                [61.0, 62.0, 63.0, 64.0]],\n",
    "                               [[65.0, 66.0, 67.0, 68.0], \n",
    "                                [69.0, 70.0, 71.0, 72.0], \n",
    "                                [73.0, 74.0, 75.0, 76.0], \n",
    "                                [77.0, 78.0, 79.0, 80.0]],\n",
    "                               [[81.0, 82.0, 83.0, 84.0], \n",
    "                                [85.0, 86.0, 87.0, 88.0], \n",
    "                                [89.0, 90.0, 91.0, 92.0], \n",
    "                                [93.0, 94.0, 95.0, 96.0]]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4, 4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch normalization layer for 2D inputs\n",
    "batch_norm = nn.BatchNorm2d(num_features=3)  # 3 channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: weight\n",
      "Tensor: Parameter containing:\n",
      "tensor([1., 1., 1.], requires_grad=True)\n",
      "Name: bias\n",
      "Tensor: Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Print out the names and tensors of the parameters in batch_norm\n",
    "for name, param in batch_norm.named_parameters():\n",
    "    print(f'Name: {name}')\n",
    "    print(f'Tensor: {param}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of learnable parameters: 6\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of learnable parameters\n",
    "num_params = sum(p.numel() for p in batch_norm.parameters())\n",
    "\n",
    "print(f'Number of learnable parameters: {num_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update weights and biases\n",
    "batch_norm.weight.data = torch.tensor([0.7, 0.4, 0.95])  # Scale (γ) per channel\n",
    "batch_norm.bias.data = torch.tensor([0.2, 0.37, 0.67])    # Shift (β) per channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: weight\n",
      "Tensor: Parameter containing:\n",
      "tensor([0.7000, 0.4000, 0.9500], requires_grad=True)\n",
      "Shape: torch.Size([3])\n",
      "Name: bias\n",
      "Tensor: Parameter containing:\n",
      "tensor([0.2000, 0.3700, 0.6700], requires_grad=True)\n",
      "Shape: torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# Print out the names and tensors of the parameters in batch_norm\n",
    "for name, param in batch_norm.named_parameters():\n",
    "    print(f'Name: {name}')\n",
    "    print(f'Tensor: {param}')\n",
    "    print(f'Shape: {param.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass through BatchNorm layer\n",
    "output = batch_norm(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean per channel: tensor([[[[32.5000]],\n",
      "\n",
      "         [[48.5000]],\n",
      "\n",
      "         [[64.5000]]]])\n",
      "Shape of mean tensor: torch.Size([1, 3, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Manual calculation of batch normalization\n",
    "mean = input_tensor.mean(dim=(0, 2, 3), keepdim=True)  # Mean per channel\n",
    "print(f'Mean per channel: {mean}')\n",
    "print(f'Shape of mean tensor: {mean.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.,  4.],\n",
      "        [ 5.,  6.,  7.,  8.],\n",
      "        [ 9., 10., 11., 12.],\n",
      "        [13., 14., 15., 16.]])\n",
      "tensor([[49., 50., 51., 52.],\n",
      "        [53., 54., 55., 56.],\n",
      "        [57., 58., 59., 60.],\n",
      "        [61., 62., 63., 64.]])\n"
     ]
    }
   ],
   "source": [
    "# First Channel\n",
    "X1C1 = input_tensor[0,0]\n",
    "print(X1C1)\n",
    "X2C1 = input_tensor[1,0]\n",
    "print(X2C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[50., 52., 54., 56.],\n",
      "        [58., 60., 62., 64.],\n",
      "        [66., 68., 70., 72.],\n",
      "        [74., 76., 78., 80.]])\n",
      "tensor(1040.)\n",
      "tensor(32.5000)\n"
     ]
    }
   ],
   "source": [
    "Sum1 = X1C1 + X2C1\n",
    "print(Sum1)\n",
    "print(Sum1.sum())\n",
    "print(Sum1.sum()/(16*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[17., 18., 19., 20.],\n",
      "        [21., 22., 23., 24.],\n",
      "        [25., 26., 27., 28.],\n",
      "        [29., 30., 31., 32.]])\n",
      "tensor([[65., 66., 67., 68.],\n",
      "        [69., 70., 71., 72.],\n",
      "        [73., 74., 75., 76.],\n",
      "        [77., 78., 79., 80.]])\n"
     ]
    }
   ],
   "source": [
    "# Second Channel\n",
    "X1C2 = input_tensor[0,1]\n",
    "print(X1C2)\n",
    "X2C2 = input_tensor[1,1]\n",
    "print(X2C2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 82.,  84.,  86.,  88.],\n",
      "        [ 90.,  92.,  94.,  96.],\n",
      "        [ 98., 100., 102., 104.],\n",
      "        [106., 108., 110., 112.]])\n",
      "tensor(1552.)\n",
      "tensor(48.5000)\n"
     ]
    }
   ],
   "source": [
    "Sum2 = X1C2 + X2C2\n",
    "print(Sum2)\n",
    "print(Sum2.sum())\n",
    "print(Sum2.sum()/(16*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[33., 34., 35., 36.],\n",
      "        [37., 38., 39., 40.],\n",
      "        [41., 42., 43., 44.],\n",
      "        [45., 46., 47., 48.]])\n",
      "tensor([[81., 82., 83., 84.],\n",
      "        [85., 86., 87., 88.],\n",
      "        [89., 90., 91., 92.],\n",
      "        [93., 94., 95., 96.]])\n"
     ]
    }
   ],
   "source": [
    "# Third Channel\n",
    "X1C3 = input_tensor[0,2]\n",
    "print(X1C3)\n",
    "X2C3 = input_tensor[1,2]\n",
    "print(X2C3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[114., 116., 118., 120.],\n",
      "        [122., 124., 126., 128.],\n",
      "        [130., 132., 134., 136.],\n",
      "        [138., 140., 142., 144.]])\n",
      "tensor(2064.)\n",
      "tensor(64.5000)\n"
     ]
    }
   ],
   "source": [
    "Sum3 = X1C3 + X2C3\n",
    "print(Sum3)\n",
    "print(Sum3.sum())\n",
    "print(Sum3.sum()/(16*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance per channel: tensor([[[[597.2500]],\n",
      "\n",
      "         [[597.2500]],\n",
      "\n",
      "         [[597.2500]]]])\n",
      "shape of variance tensor: torch.Size([1, 3, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "variance = input_tensor.var(dim=(0, 2, 3), unbiased=False, keepdim=True)  # Variance per channel\n",
    "print(f'Variance per channel: {variance}')\n",
    "print(f'shape of variance tensor: {variance.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-05\n"
     ]
    }
   ],
   "source": [
    "epsilon = batch_norm.eps  # Small constant for numerical stability\n",
    "print(epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-31.5000, -30.5000, -29.5000, -28.5000],\n",
      "          [-27.5000, -26.5000, -25.5000, -24.5000],\n",
      "          [-23.5000, -22.5000, -21.5000, -20.5000],\n",
      "          [-19.5000, -18.5000, -17.5000, -16.5000]],\n",
      "\n",
      "         [[-31.5000, -30.5000, -29.5000, -28.5000],\n",
      "          [-27.5000, -26.5000, -25.5000, -24.5000],\n",
      "          [-23.5000, -22.5000, -21.5000, -20.5000],\n",
      "          [-19.5000, -18.5000, -17.5000, -16.5000]],\n",
      "\n",
      "         [[-31.5000, -30.5000, -29.5000, -28.5000],\n",
      "          [-27.5000, -26.5000, -25.5000, -24.5000],\n",
      "          [-23.5000, -22.5000, -21.5000, -20.5000],\n",
      "          [-19.5000, -18.5000, -17.5000, -16.5000]]],\n",
      "\n",
      "\n",
      "        [[[ 16.5000,  17.5000,  18.5000,  19.5000],\n",
      "          [ 20.5000,  21.5000,  22.5000,  23.5000],\n",
      "          [ 24.5000,  25.5000,  26.5000,  27.5000],\n",
      "          [ 28.5000,  29.5000,  30.5000,  31.5000]],\n",
      "\n",
      "         [[ 16.5000,  17.5000,  18.5000,  19.5000],\n",
      "          [ 20.5000,  21.5000,  22.5000,  23.5000],\n",
      "          [ 24.5000,  25.5000,  26.5000,  27.5000],\n",
      "          [ 28.5000,  29.5000,  30.5000,  31.5000]],\n",
      "\n",
      "         [[ 16.5000,  17.5000,  18.5000,  19.5000],\n",
      "          [ 20.5000,  21.5000,  22.5000,  23.5000],\n",
      "          [ 24.5000,  25.5000,  26.5000,  27.5000],\n",
      "          [ 28.5000,  29.5000,  30.5000,  31.5000]]]])\n"
     ]
    }
   ],
   "source": [
    "print(input_tensor - mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[24.4387]],\n",
      "\n",
      "         [[24.4387]],\n",
      "\n",
      "         [[24.4387]]]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.sqrt(variance + epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-1.2889, -1.2480, -1.2071, -1.1662],\n",
      "          [-1.1253, -1.0843, -1.0434, -1.0025],\n",
      "          [-0.9616, -0.9207, -0.8798, -0.8388],\n",
      "          [-0.7979, -0.7570, -0.7161, -0.6752]],\n",
      "\n",
      "         [[-1.2889, -1.2480, -1.2071, -1.1662],\n",
      "          [-1.1253, -1.0843, -1.0434, -1.0025],\n",
      "          [-0.9616, -0.9207, -0.8798, -0.8388],\n",
      "          [-0.7979, -0.7570, -0.7161, -0.6752]],\n",
      "\n",
      "         [[-1.2889, -1.2480, -1.2071, -1.1662],\n",
      "          [-1.1253, -1.0843, -1.0434, -1.0025],\n",
      "          [-0.9616, -0.9207, -0.8798, -0.8388],\n",
      "          [-0.7979, -0.7570, -0.7161, -0.6752]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6752,  0.7161,  0.7570,  0.7979],\n",
      "          [ 0.8388,  0.8798,  0.9207,  0.9616],\n",
      "          [ 1.0025,  1.0434,  1.0843,  1.1253],\n",
      "          [ 1.1662,  1.2071,  1.2480,  1.2889]],\n",
      "\n",
      "         [[ 0.6752,  0.7161,  0.7570,  0.7979],\n",
      "          [ 0.8388,  0.8798,  0.9207,  0.9616],\n",
      "          [ 1.0025,  1.0434,  1.0843,  1.1253],\n",
      "          [ 1.1662,  1.2071,  1.2480,  1.2889]],\n",
      "\n",
      "         [[ 0.6752,  0.7161,  0.7570,  0.7979],\n",
      "          [ 0.8388,  0.8798,  0.9207,  0.9616],\n",
      "          [ 1.0025,  1.0434,  1.0843,  1.1253],\n",
      "          [ 1.1662,  1.2071,  1.2480,  1.2889]]]])\n"
     ]
    }
   ],
   "source": [
    "# Normalize: (x - mean) / sqrt(variance + epsilon)\n",
    "x_normalized = (input_tensor - mean) / torch.sqrt(variance + epsilon)\n",
    "print(x_normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.7000]],\n",
      "\n",
      "         [[0.4000]],\n",
      "\n",
      "         [[0.9500]]]], grad_fn=<ViewBackward0>)\n",
      "shape of w1: torch.Size([1, 3, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "w1 = batch_norm.weight.view(1,-1,1,1)\n",
    "print(w1)\n",
    "print(f'shape of w1: {w1.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.9023, -0.8736, -0.8450, -0.8163],\n",
       "          [-0.7877, -0.7590, -0.7304, -0.7018],\n",
       "          [-0.6731, -0.6445, -0.6158, -0.5872],\n",
       "          [-0.5585, -0.5299, -0.5013, -0.4726]],\n",
       "\n",
       "         [[-0.5156, -0.4992, -0.4828, -0.4665],\n",
       "          [-0.4501, -0.4337, -0.4174, -0.4010],\n",
       "          [-0.3846, -0.3683, -0.3519, -0.3355],\n",
       "          [-0.3192, -0.3028, -0.2864, -0.2701]],\n",
       "\n",
       "         [[-1.2245, -1.1856, -1.1467, -1.1079],\n",
       "          [-1.0690, -1.0301, -0.9913, -0.9524],\n",
       "          [-0.9135, -0.8746, -0.8358, -0.7969],\n",
       "          [-0.7580, -0.7191, -0.6803, -0.6414]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4726,  0.5013,  0.5299,  0.5585],\n",
       "          [ 0.5872,  0.6158,  0.6445,  0.6731],\n",
       "          [ 0.7018,  0.7304,  0.7590,  0.7877],\n",
       "          [ 0.8163,  0.8450,  0.8736,  0.9023]],\n",
       "\n",
       "         [[ 0.2701,  0.2864,  0.3028,  0.3192],\n",
       "          [ 0.3355,  0.3519,  0.3683,  0.3846],\n",
       "          [ 0.4010,  0.4174,  0.4337,  0.4501],\n",
       "          [ 0.4665,  0.4828,  0.4992,  0.5156]],\n",
       "\n",
       "         [[ 0.6414,  0.6803,  0.7191,  0.7580],\n",
       "          [ 0.7969,  0.8358,  0.8746,  0.9135],\n",
       "          [ 0.9524,  0.9913,  1.0301,  1.0690],\n",
       "          [ 1.1079,  1.1467,  1.1856,  1.2245]]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_norm.weight.view(1, -1, 1, 1) * x_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-7.0226e-01, -6.7361e-01, -6.4497e-01, -6.1633e-01],\n",
      "          [-5.8769e-01, -5.5904e-01, -5.3040e-01, -5.0176e-01],\n",
      "          [-4.7311e-01, -4.4447e-01, -4.1583e-01, -3.8718e-01],\n",
      "          [-3.5854e-01, -3.2990e-01, -3.0125e-01, -2.7261e-01]],\n",
      "\n",
      "         [[-1.4558e-01, -1.2921e-01, -1.1284e-01, -9.6473e-02],\n",
      "          [-8.0106e-02, -6.3738e-02, -4.7371e-02, -3.1003e-02],\n",
      "          [-1.4636e-02,  1.7316e-03,  1.8099e-02,  3.4467e-02],\n",
      "          [ 5.0834e-02,  6.7202e-02,  8.3569e-02,  9.9937e-02]],\n",
      "\n",
      "         [[-5.5449e-01, -5.1562e-01, -4.7675e-01, -4.3787e-01],\n",
      "          [-3.9900e-01, -3.6013e-01, -3.2126e-01, -2.8238e-01],\n",
      "          [-2.4351e-01, -2.0464e-01, -1.6576e-01, -1.2689e-01],\n",
      "          [-8.8019e-02, -4.9146e-02, -1.0274e-02,  2.8599e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.7261e-01,  7.0125e-01,  7.2990e-01,  7.5854e-01],\n",
      "          [ 7.8718e-01,  8.1583e-01,  8.4447e-01,  8.7311e-01],\n",
      "          [ 9.0176e-01,  9.3040e-01,  9.5904e-01,  9.8769e-01],\n",
      "          [ 1.0163e+00,  1.0450e+00,  1.0736e+00,  1.1023e+00]],\n",
      "\n",
      "         [[ 6.4006e-01,  6.5643e-01,  6.7280e-01,  6.8917e-01],\n",
      "          [ 7.0553e-01,  7.2190e-01,  7.3827e-01,  7.5464e-01],\n",
      "          [ 7.7100e-01,  7.8737e-01,  8.0374e-01,  8.2011e-01],\n",
      "          [ 8.3647e-01,  8.5284e-01,  8.6921e-01,  8.8558e-01]],\n",
      "\n",
      "         [[ 1.3114e+00,  1.3503e+00,  1.3891e+00,  1.4280e+00],\n",
      "          [ 1.4669e+00,  1.5058e+00,  1.5446e+00,  1.5835e+00],\n",
      "          [ 1.6224e+00,  1.6613e+00,  1.7001e+00,  1.7390e+00],\n",
      "          [ 1.7779e+00,  1.8167e+00,  1.8556e+00,  1.8945e+00]]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Scale and shift: γ * x_normalized + β\n",
    "manual_output = batch_norm.weight.view(1, -1, 1, 1) * x_normalized + batch_norm.bias.view(1, -1, 1, 1)\n",
    "print(manual_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch Normalization Output (PyTorch):\n",
      "tensor([[[[-7.0226e-01, -6.7361e-01, -6.4497e-01, -6.1633e-01],\n",
      "          [-5.8769e-01, -5.5904e-01, -5.3040e-01, -5.0176e-01],\n",
      "          [-4.7311e-01, -4.4447e-01, -4.1583e-01, -3.8718e-01],\n",
      "          [-3.5854e-01, -3.2990e-01, -3.0125e-01, -2.7261e-01]],\n",
      "\n",
      "         [[-1.4558e-01, -1.2921e-01, -1.1284e-01, -9.6473e-02],\n",
      "          [-8.0106e-02, -6.3738e-02, -4.7371e-02, -3.1003e-02],\n",
      "          [-1.4636e-02,  1.7316e-03,  1.8099e-02,  3.4467e-02],\n",
      "          [ 5.0834e-02,  6.7202e-02,  8.3569e-02,  9.9937e-02]],\n",
      "\n",
      "         [[-5.5449e-01, -5.1562e-01, -4.7675e-01, -4.3787e-01],\n",
      "          [-3.9900e-01, -3.6013e-01, -3.2126e-01, -2.8238e-01],\n",
      "          [-2.4351e-01, -2.0464e-01, -1.6576e-01, -1.2689e-01],\n",
      "          [-8.8019e-02, -4.9146e-02, -1.0273e-02,  2.8599e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.7261e-01,  7.0125e-01,  7.2990e-01,  7.5854e-01],\n",
      "          [ 7.8718e-01,  8.1583e-01,  8.4447e-01,  8.7311e-01],\n",
      "          [ 9.0176e-01,  9.3040e-01,  9.5904e-01,  9.8769e-01],\n",
      "          [ 1.0163e+00,  1.0450e+00,  1.0736e+00,  1.1023e+00]],\n",
      "\n",
      "         [[ 6.4006e-01,  6.5643e-01,  6.7280e-01,  6.8917e-01],\n",
      "          [ 7.0553e-01,  7.2190e-01,  7.3827e-01,  7.5464e-01],\n",
      "          [ 7.7100e-01,  7.8737e-01,  8.0374e-01,  8.2011e-01],\n",
      "          [ 8.3647e-01,  8.5284e-01,  8.6921e-01,  8.8558e-01]],\n",
      "\n",
      "         [[ 1.3114e+00,  1.3503e+00,  1.3891e+00,  1.4280e+00],\n",
      "          [ 1.4669e+00,  1.5058e+00,  1.5446e+00,  1.5835e+00],\n",
      "          [ 1.6224e+00,  1.6613e+00,  1.7001e+00,  1.7390e+00],\n",
      "          [ 1.7779e+00,  1.8167e+00,  1.8556e+00,  1.8945e+00]]]],\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# # Print results\n",
    "# print(\"Input Tensor:\")\n",
    "# print(input_tensor)\n",
    "# print(\"\\nMean per Channel:\")\n",
    "# print(mean)\n",
    "# print(\"\\nVariance per Channel:\")\n",
    "# print(variance)\n",
    "# print(\"\\nNormalized Value (x_normalized):\")\n",
    "# print(x_normalized)\n",
    "print(\"\\nBatch Normalization Output (PyTorch):\")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch Normalization Output (Manual Calculation):\n",
      "tensor([[[[-7.0226e-01, -6.7361e-01, -6.4497e-01, -6.1633e-01],\n",
      "          [-5.8769e-01, -5.5904e-01, -5.3040e-01, -5.0176e-01],\n",
      "          [-4.7311e-01, -4.4447e-01, -4.1583e-01, -3.8718e-01],\n",
      "          [-3.5854e-01, -3.2990e-01, -3.0125e-01, -2.7261e-01]],\n",
      "\n",
      "         [[-1.4558e-01, -1.2921e-01, -1.1284e-01, -9.6473e-02],\n",
      "          [-8.0106e-02, -6.3738e-02, -4.7371e-02, -3.1003e-02],\n",
      "          [-1.4636e-02,  1.7316e-03,  1.8099e-02,  3.4467e-02],\n",
      "          [ 5.0834e-02,  6.7202e-02,  8.3569e-02,  9.9937e-02]],\n",
      "\n",
      "         [[-5.5449e-01, -5.1562e-01, -4.7675e-01, -4.3787e-01],\n",
      "          [-3.9900e-01, -3.6013e-01, -3.2126e-01, -2.8238e-01],\n",
      "          [-2.4351e-01, -2.0464e-01, -1.6576e-01, -1.2689e-01],\n",
      "          [-8.8019e-02, -4.9146e-02, -1.0274e-02,  2.8599e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.7261e-01,  7.0125e-01,  7.2990e-01,  7.5854e-01],\n",
      "          [ 7.8718e-01,  8.1583e-01,  8.4447e-01,  8.7311e-01],\n",
      "          [ 9.0176e-01,  9.3040e-01,  9.5904e-01,  9.8769e-01],\n",
      "          [ 1.0163e+00,  1.0450e+00,  1.0736e+00,  1.1023e+00]],\n",
      "\n",
      "         [[ 6.4006e-01,  6.5643e-01,  6.7280e-01,  6.8917e-01],\n",
      "          [ 7.0553e-01,  7.2190e-01,  7.3827e-01,  7.5464e-01],\n",
      "          [ 7.7100e-01,  7.8737e-01,  8.0374e-01,  8.2011e-01],\n",
      "          [ 8.3647e-01,  8.5284e-01,  8.6921e-01,  8.8558e-01]],\n",
      "\n",
      "         [[ 1.3114e+00,  1.3503e+00,  1.3891e+00,  1.4280e+00],\n",
      "          [ 1.4669e+00,  1.5058e+00,  1.5446e+00,  1.5835e+00],\n",
      "          [ 1.6224e+00,  1.6613e+00,  1.7001e+00,  1.7390e+00],\n",
      "          [ 1.7779e+00,  1.8167e+00,  1.8556e+00,  1.8945e+00]]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBatch Normalization Output (Manual Calculation):\")\n",
    "print(manual_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
